{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "re: I found 1 face(s) in this photograph.\n",
      "start_time 1549870431.0066483\n",
      "--- 12.589848279953003 seconds ---\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "####동영상 프레임 나눔 -> 나눈 프레임 사진들 -> opencv로 입술 추출####\n",
    "###############################################################\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "#시간 측정\n",
    "start_time = time.time() \n",
    "#------------------------\n",
    "\n",
    "path = 'tensorflow/Inception_V3_retraining/test_data/'\n",
    "\n",
    "#동영상 불러오기\n",
    "vidcap = cv2.VideoCapture(path + 'an.mp4')\n",
    "success,images = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "#프레임 하나씩 추출(마지막은 false로 정지)\n",
    "while success:\n",
    "    #프레임 이미지 저장 (count 0 부터)\n",
    "    cv2.imwrite(path + \"frame%10d.jpg\" % count, images)     # save f\n",
    "    success,images = vidcap.read()\n",
    "    ###########################################\n",
    "    #print('Read a new frame: ', success)\n",
    "    ###########################################\n",
    "    \n",
    "    #얼굴 인식을 위한 이미지 불러오기\n",
    "    image = face_recognition.load_image_file(path + \"frame%10d.jpg\" % count)\n",
    "\n",
    "    #얼굴의 눈, 코, 입을 기준으로\n",
    "    #4개의 좌표로 사진을 자름(top, left, bottom, right)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "    if len(face_locations) == 1:\n",
    "        print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))   \n",
    "    \n",
    "    else:\n",
    "        print(\"I found {} face(s) in this photograph.\".format(len(face_locations))) \n",
    "        \n",
    "        img = cv2.imread(path + 'frame%10d.jpg' % count, 0)\n",
    "        \n",
    "        rows,cols = img.shape\n",
    "\n",
    "        M = cv2.getRotationMatrix2D((cols/2,rows/2),-90,1)\n",
    "        dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        cv2.imwrite(path + 'frame%10d.jpg' % count, dst)\n",
    "        \n",
    "        image = face_recognition.load_image_file(path + \"frame%10d.jpg\" % count)\n",
    "        \n",
    "        face_locations = face_recognition.face_locations(image)\n",
    "        print(\"re: I found {} face(s) in this photograph.\".format(len(face_locations))) \n",
    "        \n",
    "    ###########################################\n",
    "    #print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "    ###########################################\n",
    "\n",
    "    #얼굴의 개수 for문 진행(1개 이상 가능)\n",
    "    for face_location in face_locations:\n",
    "        #top, right, bottom, left순으로 저장 ex)(93, 439, 316, 216)\n",
    "        top, right, bottom, left = face_location\n",
    "        ###########################################\n",
    "        #print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "        ###########################################\n",
    "\n",
    "        #좌표로 얼굴 사진 자름\n",
    "        face_image = image[top:bottom, left:right]\n",
    "        pil_image = Image.fromarray(face_image)\n",
    "    \n",
    "    #PIL -> array 이미지 변환\n",
    "    imgarr = np.array(pil_image) \n",
    "    \n",
    "    #openCV를 사용하기 위한 얼굴 인식 호출\n",
    "    face_landmarks_list = face_recognition.face_landmarks(imgarr)\n",
    "\n",
    "    for face_landmarks in face_landmarks_list:\n",
    "        lip_left_point = min(face_landmarks['top_lip'])[0] - 20\n",
    "        lip_right_point = max(face_landmarks['top_lip'])[0] + 20\n",
    "        lip_top_point = min(face_landmarks['top_lip'])[1] - 20\n",
    "        lip_bottom_point = min(face_landmarks['top_lip'])[1] + 65\n",
    "\n",
    "        img_color = np.array(pil_image) \n",
    "        \n",
    "        test_image = img_color[lip_top_point:lip_bottom_point, lip_left_point:lip_right_point]\n",
    "        #final_image = Image.fromarray(test_image)\n",
    "\n",
    "        #결과 이미지 저장\n",
    "        cv2.imwrite(path + \"frame%10d.jpg\" % count, test_image)\n",
    "    \n",
    "        #다음 사진\n",
    "        count += 1\n",
    "\n",
    "        #plt.imshow(img_result)\n",
    "        #plt.show()\n",
    "    \n",
    "#----------------------------\n",
    "#종료부분 코드\n",
    "print(\"start_time\", start_time) #출력해보면, 시간형식이 사람이 읽기 힘든 일련번호형식입니다.\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
